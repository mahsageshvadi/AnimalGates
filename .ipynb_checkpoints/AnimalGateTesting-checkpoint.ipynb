{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "475ff28c",
   "metadata": {},
   "source": [
    "# Import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acc1620b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.applications import imagenet_utils\n",
    "from huggingface_hub import from_pretrained_fastai\n",
    "import requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c39e934d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import torchvision\n",
    "from torchvision import transforms\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a311a2",
   "metadata": {},
   "source": [
    "# Load the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3a05892d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "image_path = 'dataSamples/'\n",
    "\n",
    "def prepare_image(file):\n",
    "    img = Image.open(file)\n",
    "    img = img.resize((224, 224))  # Resize the image to (224, 224)\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array_expanded_dims = np.expand_dims(img_array, axis=0)\n",
    "    return tf.keras.applications.mobilenet.preprocess_input(img_array_expanded_dims)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "77597a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_file_name = 'Persian_12.jpg'\n",
    "current_image = image_path + image_file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e867321",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.open(image_path + image_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d369dd",
   "metadata": {},
   "source": [
    "# Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "130dd1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model \n",
    "mobileNetModel = tf.keras.applications.mobilenet.MobileNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "11b41874",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMobileNetResults(image):\n",
    "    preprocessed_image = prepare_image(image)\n",
    "    results = mobileNetModel.predict(preprocessed_image)\n",
    "    return imagenet_utils.decode_predictions(results)[0][0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7506f59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "48a029ce",
   "metadata": {},
   "source": [
    "# Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7178ac79",
   "metadata": {},
   "outputs": [],
   "source": [
    "API_URL = \"https://api-inference.huggingface.co/models/dima806/67_cat_breeds_image_detection\"\n",
    "headers = {\"Authorization\": \"Bearer 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\"}\n",
    "\n",
    "def query(filename):\n",
    "    with open(filename, \"rb\") as f:\n",
    "        data = f.read()\n",
    "    response = requests.post(API_URL, headers=headers, data=data)\n",
    "    return response.json()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "9c6d75c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getHuggingFaceResults1(image):\n",
    "    output = query(image)\n",
    "    return output[0]['label']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c91079a",
   "metadata": {},
   "source": [
    "# Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17065ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = from_pretrained_fastai(\"codingmoh/cat-breed-identifier\")\n",
    "model.predict(image_path + image_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630ae7d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e466cc3d",
   "metadata": {},
   "source": [
    "# Model 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7654e499",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mahsa/miniconda3/envs/torchtens/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/mahsa/miniconda3/envs/torchtens/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ModelHead(\n",
       "  (fc1): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "  (relu1): ReLU()\n",
       "  (fc2): Linear(in_features=1024, out_features=512, bias=True)\n",
       "  (relu2): ReLU()\n",
       "  (fc3): Linear(in_features=512, out_features=12, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = torchvision.models.resnet50(pretrained=True).to(device)\n",
    "\n",
    "# freeze the backbone\n",
    "for parameter in model.parameters():\n",
    "    parameter.requires_grad = False\n",
    "\n",
    "\n",
    "class ModelHead(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, n_classes):\n",
    "        super(ModelHead, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(input_dim, hidden_dim)\n",
    "        self.relu1 = torch.nn.ReLU()\n",
    "        self.fc2 = torch.nn.Linear(hidden_dim, hidden_dim // 2)\n",
    "        self.relu2 = torch.nn.ReLU()\n",
    "        self.fc3 = torch.nn.Linear(hidden_dim // 2, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model.fc = ModelHead(2048, 1024, 12)\n",
    "model.fc.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d393a8a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): ModelHead(\n",
       "    (fc1): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "    (relu1): ReLU()\n",
       "    (fc2): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    (relu2): ReLU()\n",
       "    (fc3): Linear(in_features=512, out_features=12, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_SAVE_PATH = 'checkpoints'\n",
    "model.load_state_dict(torch.load(os.path.join(MODEL_SAVE_PATH, 'best_checkpoint.pth')))\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c08df382",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrepareData():\n",
    "    def __init__(self):\n",
    "        self.keywords = ['Abyssinian', 'Bengal', 'Birman', 'Bombay',\n",
    "                         'British Shorthair', 'Egyptian Mau', 'Maine Coon', 'Persian',\n",
    "                         'Ragdoll', 'Russian Blue', 'Siamese', 'Sphynx']\n",
    "\n",
    "\n",
    "    def removeDogData(self):\n",
    "\n",
    "        directory_path = 'images'\n",
    "        all_files = os.listdir(directory_path)\n",
    "        filtered_files = [file for file in all_files if any(keyword.lower() in file.lower() for keyword in self.keywords)]\n",
    "\n",
    "        for file in all_files:\n",
    "            if file not in filtered_files:\n",
    "                file_path = os.path.join(directory_path, file)\n",
    "                os.remove(file_path)\n",
    "\n",
    "    def cleanTrainTestNameFile(self, file_path):\n",
    "\n",
    "        with open(file_path, 'r') as file:\n",
    "            lines = file.readlines()\n",
    "\n",
    "        filtered_lines = [line for line in lines if any(keyword.lower() in line.lower() for keyword in self.keywords)]\n",
    "\n",
    "        with open(file_path, 'w') as file:\n",
    "            file.writelines(filtered_lines)\n",
    "\n",
    "    def trainTestSplitBasedOnFile(self):\n",
    "\n",
    "        image_folder = 'images'\n",
    "\n",
    "        test_file_path = 'test.txt'\n",
    "        eval_file_path = 'trainval.txt'\n",
    "\n",
    "        train_folder = 'train'\n",
    "        test_folder = 'test'\n",
    "        eval_folder = 'eval'\n",
    "\n",
    "        for folder in [train_folder, test_folder, eval_folder]:\n",
    "            os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "        train_ratio = 0.7\n",
    "        test_ratio = 0.15\n",
    "        val_ratio = 0.15\n",
    "\n",
    "\n",
    "\n",
    "        # Iterate through each class\n",
    "        for cat_class in self.keywords:\n",
    "            # Get the list of images for the current class\n",
    "            class_images = [file for file in os.listdir(image_folder) if file.startswith(f\"{cat_class}_\")]\n",
    "\n",
    "            # Shuffle the list of images for randomness\n",
    "            random.shuffle(class_images)\n",
    "\n",
    "            # Calculate the split points based on the ratios\n",
    "            train_split = int(len(class_images) * train_ratio)\n",
    "            test_split = int(len(class_images) * (train_ratio + test_ratio))\n",
    "\n",
    "            # Split the images into train, test, and validation sets\n",
    "            train_images = class_images[:train_split]\n",
    "            test_images = class_images[train_split:test_split]\n",
    "            val_images = class_images[test_split:]\n",
    "\n",
    "            # Move the images to their respective folders\n",
    "            for image in train_images:\n",
    "                shutil.move(os.path.join(image_folder, image), os.path.join(train_folder, image))\n",
    "\n",
    "            for image in test_images:\n",
    "                shutil.move(os.path.join(image_folder, image), os.path.join(test_folder, image))\n",
    "\n",
    "            for image in val_images:\n",
    "                shutil.move(os.path.join(image_folder, image), os.path.join(eval_folder, image))\n",
    "\n",
    "\n",
    "    def splitData(self, folderName):\n",
    "\n",
    "        original_folder = folderName\n",
    "\n",
    "        organized_folder = 'Data/'+ folderName\n",
    "\n",
    "        os.makedirs(organized_folder, exist_ok=True)\n",
    "\n",
    "        for cat_class in self.keywords:\n",
    "            # Create a subfolder for the current class\n",
    "            class_folder = os.path.join(organized_folder, cat_class)\n",
    "            os.makedirs(class_folder, exist_ok=True)\n",
    "\n",
    "            # Get the list of images for the current class\n",
    "            class_images = [file for file in os.listdir(original_folder) if file.startswith(f\"{cat_class}_\")]\n",
    "\n",
    "            # Move the images to the class subfolder\n",
    "            for image in class_images:\n",
    "                source_path = os.path.join(original_folder, image)\n",
    "                destination_path = os.path.join(class_folder, image)\n",
    "                shutil.move(source_path, destination_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0f9b20fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "transform_valid = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "])\n",
    "prepareData = PrepareData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "adb61a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getOurModelResult(image_path):\n",
    "    # Load and transform the image\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    input_tensor = transform_valid(image)\n",
    "    input_batch = input_tensor.unsqueeze(0).to(device)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model(input_batch)\n",
    "\n",
    "    # Get the predicted class\n",
    "    _, predicted_class = torch.max(output, 1)\n",
    "    predicted_class = predicted_class.item()\n",
    "\n",
    "    return prepareData.keywords[predicted_class]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "675e3334",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dataSamples/Egyptian-Mau.jpeg'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "fc559125",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def predict_all_models(current_image):\n",
    "    \n",
    "    predicted_class_ResNet =getMobileNetResults(current_image)\n",
    "    print(\"ResNet Prediction:\\t\\t\"+ predicted_class_ResNet)\n",
    "    \n",
    "    predicted_class_HuggingFace = getHuggingFaceResults1(current_image)\n",
    "    print(\"Hugging Face Prediction:\\t\"+ predicted_class_HuggingFace)\n",
    "\n",
    "    predicted_class_ourModel = getOurModelResult(current_image)\n",
    "    print(\"Our Model Prediction:\\t\\t\" + predicted_class_ourModel)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "66419bc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 28ms/step\n",
      "ResNet Prediction:\t\tPersian_cat\n",
      "Hugging Face Prediction:\tPersian\n",
      "Our Model Prediction:\t\tBritish Shorthair\n"
     ]
    }
   ],
   "source": [
    "predict_all_models(current_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b007761f",
   "metadata": {},
   "source": [
    "# Plot for data distribution for the second model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4bb647b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e32cfdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_distribution = [255, 991, 149, 5295, 19, 135, 254, 2477, 227, 1835, 567, 344, 8, 3468, 4, 84, 24, 3,\n",
    "                      171, 17, 119, 3230, 3152, 4499, 5482, 53000, 305, 471, 1184, 184, 1301, 127, 25, 68, 17, \n",
    "                      1418, 2059, 181, 148, 580, 118, 37, 491,\n",
    "                      101, 4018, 111, 134, 2669, 1870, 380, 77, 2888, 189, 94, 22, 1625, 36, 206, 3012, 2256]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e726d1d",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'matplotlib' has no attribute 'hist'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhist\u001b[49m(class_distribution)\n",
      "File \u001b[0;32m~/miniconda3/envs/torchtens/lib/python3.10/site-packages/matplotlib/_api/__init__.py:226\u001b[0m, in \u001b[0;36mcaching_module_getattr.<locals>.__getattr__\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m props:\n\u001b[1;32m    225\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m props[name]\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__get__\u001b[39m(instance)\n\u001b[0;32m--> 226\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodule \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__module__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m has no attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'matplotlib' has no attribute 'hist'"
     ]
    }
   ],
   "source": [
    "plt.hist(class_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67cbebec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
