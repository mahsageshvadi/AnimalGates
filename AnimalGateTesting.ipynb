{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "475ff28c",
   "metadata": {},
   "source": [
    "# Import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acc1620b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.applications import imagenet_utils\n",
    "from huggingface_hub import from_pretrained_fastai\n",
    "import requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c39e934d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import torchvision\n",
    "from torchvision import transforms\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a311a2",
   "metadata": {},
   "source": [
    "# Load the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3a05892d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "image_path = 'dataSamples/'\n",
    "\n",
    "def prepare_image(file):\n",
    "    img = Image.open(file)\n",
    "    img = img.resize((224, 224))  # Resize the image to (224, 224)\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array_expanded_dims = np.expand_dims(img_array, axis=0)\n",
    "    return tf.keras.applications.mobilenet.preprocess_input(img_array_expanded_dims)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "77597a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_file_name = 'Persian_12.jpg'\n",
    "current_image = image_path + image_file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e867321",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.open(image_path + image_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d369dd",
   "metadata": {},
   "source": [
    "# Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "130dd1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model \n",
    "mobileNetModel = tf.keras.applications.mobilenet.MobileNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "11b41874",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMobileNetResults(image):\n",
    "    preprocessed_image = prepare_image(image)\n",
    "    results = mobileNetModel.predict(preprocessed_image)\n",
    "    return imagenet_utils.decode_predictions(results)[0][0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7506f59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "48a029ce",
   "metadata": {},
   "source": [
    "# Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7178ac79",
   "metadata": {},
   "outputs": [],
   "source": [
    "API_URL = \"https://api-inference.huggingface.co/models/dima806/67_cat_breeds_image_detection\"\n",
    "headers = {\"Authorization\": \"Bearer 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\"}\n",
    "\n",
    "def query(filename):\n",
    "    with open(filename, \"rb\") as f:\n",
    "        data = f.read()\n",
    "    response = requests.post(API_URL, headers=headers, data=data)\n",
    "    return response.json()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "9c6d75c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getHuggingFaceResults1(image):\n",
    "    output = query(image)\n",
    "    return output[0]['label']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c91079a",
   "metadata": {},
   "source": [
    "# Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17065ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = from_pretrained_fastai(\"codingmoh/cat-breed-identifier\")\n",
    "model.predict(image_path + image_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630ae7d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e466cc3d",
   "metadata": {},
   "source": [
    "# Model 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7654e499",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mahsa/miniconda3/envs/torchtens/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/mahsa/miniconda3/envs/torchtens/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ModelHead(\n",
       "  (fc1): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "  (relu1): ReLU()\n",
       "  (fc2): Linear(in_features=1024, out_features=512, bias=True)\n",
       "  (relu2): ReLU()\n",
       "  (fc3): Linear(in_features=512, out_features=12, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = torchvision.models.resnet50(pretrained=True).to(device)\n",
    "\n",
    "# freeze the backbone\n",
    "for parameter in model.parameters():\n",
    "    parameter.requires_grad = False\n",
    "\n",
    "\n",
    "class ModelHead(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, n_classes):\n",
    "        super(ModelHead, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(input_dim, hidden_dim)\n",
    "        self.relu1 = torch.nn.ReLU()\n",
    "        self.fc2 = torch.nn.Linear(hidden_dim, hidden_dim // 2)\n",
    "        self.relu2 = torch.nn.ReLU()\n",
    "        self.fc3 = torch.nn.Linear(hidden_dim // 2, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model.fc = ModelHead(2048, 1024, 12)\n",
    "model.fc.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d393a8a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): ModelHead(\n",
       "    (fc1): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "    (relu1): ReLU()\n",
       "    (fc2): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    (relu2): ReLU()\n",
       "    (fc3): Linear(in_features=512, out_features=12, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_SAVE_PATH = 'checkpoints'\n",
    "model.load_state_dict(torch.load(os.path.join(MODEL_SAVE_PATH, 'best_checkpoint.pth')))\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c08df382",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrepareData():\n",
    "    def __init__(self):\n",
    "        self.keywords = ['Abyssinian', 'Bengal', 'Birman', 'Bombay',\n",
    "                         'British Shorthair', 'Egyptian Mau', 'Maine Coon', 'Persian',\n",
    "                         'Ragdoll', 'Russian Blue', 'Siamese', 'Sphynx']\n",
    "\n",
    "\n",
    "    def removeDogData(self):\n",
    "\n",
    "        directory_path = 'images'\n",
    "        all_files = os.listdir(directory_path)\n",
    "        filtered_files = [file for file in all_files if any(keyword.lower() in file.lower() for keyword in self.keywords)]\n",
    "\n",
    "        for file in all_files:\n",
    "            if file not in filtered_files:\n",
    "                file_path = os.path.join(directory_path, file)\n",
    "                os.remove(file_path)\n",
    "\n",
    "    def cleanTrainTestNameFile(self, file_path):\n",
    "\n",
    "        with open(file_path, 'r') as file:\n",
    "            lines = file.readlines()\n",
    "\n",
    "        filtered_lines = [line for line in lines if any(keyword.lower() in line.lower() for keyword in self.keywords)]\n",
    "\n",
    "        with open(file_path, 'w') as file:\n",
    "            file.writelines(filtered_lines)\n",
    "\n",
    "    def trainTestSplitBasedOnFile(self):\n",
    "\n",
    "        image_folder = 'images'\n",
    "\n",
    "        test_file_path = 'test.txt'\n",
    "        eval_file_path = 'trainval.txt'\n",
    "\n",
    "        train_folder = 'train'\n",
    "        test_folder = 'test'\n",
    "        eval_folder = 'eval'\n",
    "\n",
    "        for folder in [train_folder, test_folder, eval_folder]:\n",
    "            os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "        train_ratio = 0.7\n",
    "        test_ratio = 0.15\n",
    "        val_ratio = 0.15\n",
    "\n",
    "\n",
    "\n",
    "        # Iterate through each class\n",
    "        for cat_class in self.keywords:\n",
    "            # Get the list of images for the current class\n",
    "            class_images = [file for file in os.listdir(image_folder) if file.startswith(f\"{cat_class}_\")]\n",
    "\n",
    "            # Shuffle the list of images for randomness\n",
    "            random.shuffle(class_images)\n",
    "\n",
    "            # Calculate the split points based on the ratios\n",
    "            train_split = int(len(class_images) * train_ratio)\n",
    "            test_split = int(len(class_images) * (train_ratio + test_ratio))\n",
    "\n",
    "            # Split the images into train, test, and validation sets\n",
    "            train_images = class_images[:train_split]\n",
    "            test_images = class_images[train_split:test_split]\n",
    "            val_images = class_images[test_split:]\n",
    "\n",
    "            # Move the images to their respective folders\n",
    "            for image in train_images:\n",
    "                shutil.move(os.path.join(image_folder, image), os.path.join(train_folder, image))\n",
    "\n",
    "            for image in test_images:\n",
    "                shutil.move(os.path.join(image_folder, image), os.path.join(test_folder, image))\n",
    "\n",
    "            for image in val_images:\n",
    "                shutil.move(os.path.join(image_folder, image), os.path.join(eval_folder, image))\n",
    "\n",
    "\n",
    "    def splitData(self, folderName):\n",
    "\n",
    "        original_folder = folderName\n",
    "\n",
    "        organized_folder = 'Data/'+ folderName\n",
    "\n",
    "        os.makedirs(organized_folder, exist_ok=True)\n",
    "\n",
    "        for cat_class in self.keywords:\n",
    "            # Create a subfolder for the current class\n",
    "            class_folder = os.path.join(organized_folder, cat_class)\n",
    "            os.makedirs(class_folder, exist_ok=True)\n",
    "\n",
    "            # Get the list of images for the current class\n",
    "            class_images = [file for file in os.listdir(original_folder) if file.startswith(f\"{cat_class}_\")]\n",
    "\n",
    "            # Move the images to the class subfolder\n",
    "            for image in class_images:\n",
    "                source_path = os.path.join(original_folder, image)\n",
    "                destination_path = os.path.join(class_folder, image)\n",
    "                shutil.move(source_path, destination_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0f9b20fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "transform_valid = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "])\n",
    "prepareData = PrepareData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "adb61a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getOurModelResult(image_path):\n",
    "    # Load and transform the image\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    input_tensor = transform_valid(image)\n",
    "    input_batch = input_tensor.unsqueeze(0).to(device)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model(input_batch)\n",
    "\n",
    "    # Get the predicted class\n",
    "    _, predicted_class = torch.max(output, 1)\n",
    "    predicted_class = predicted_class.item()\n",
    "\n",
    "    return prepareData.keywords[predicted_class]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "675e3334",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dataSamples/Egyptian-Mau.jpeg'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "fc559125",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def predict_all_models(current_image):\n",
    "    \n",
    "    predicted_class_ResNet =getMobileNetResults(current_image)\n",
    "    print(\"ResNet Prediction:\\t\\t\"+ predicted_class_ResNet)\n",
    "    \n",
    "    predicted_class_HuggingFace = getHuggingFaceResults1(current_image)\n",
    "    print(\"Hugging Face Prediction:\\t\"+ predicted_class_HuggingFace)\n",
    "\n",
    "    predicted_class_ourModel = getOurModelResult(current_image)\n",
    "    print(\"Our Model Prediction:\\t\\t\" + predicted_class_ourModel)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "66419bc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 28ms/step\n",
      "ResNet Prediction:\t\tPersian_cat\n",
      "Hugging Face Prediction:\tPersian\n",
      "Our Model Prediction:\t\tBritish Shorthair\n"
     ]
    }
   ],
   "source": [
    "predict_all_models(current_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b007761f",
   "metadata": {},
   "source": [
    "# Plot for data distribution for the second model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4bb647b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e32cfdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_distribution = [255, 991, 149, 5295, 19, 135, 254, 2477, 227, 1835, 567, 344, 8, 3468, 4, 84, 24, 3,\n",
    "                      171, 17, 119, 3230, 3152, 4499, 5482, 53000, 305, 471, 1184, 184, 1301, 127, 25, 68, 17, \n",
    "                      1418, 2059, 181, 148, 580, 118, 37, 491,\n",
    "                      101, 4018, 111, 134, 2669, 1870, 380, 77, 2888, 189, 94, 22, 1625, 36, 206, 3012, 2256]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e726d1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(class_distribution, bins=20, color='pink', edgecolor='black')\n",
    "plt.title('Class Distribution Histogram')\n",
    "plt.xlabel('Number of Images in a Class')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67cbebec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
